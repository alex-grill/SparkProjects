{"cells":[{"cell_type":"markdown","source":["###General Instructions\nThe UCI Machine Learning Repository makes available a popular dataset identifying various properties of three cultivars of Italian wine grapes: https://archive.ics.uci.edu/ml/datasets/Wine. These can be used to build a multi-class identifier with which measurements of these properties can be used to predict which cultivar is being observed.\n\nThe values in this dataset are:</p>\n\n0. Cultivar\n1. Alcohol\n2. Malic acid\n3. Ash\n4. Alcalinity of ash\n5. Magnesium\n6. Total phenols\n7. Flavanoids\n8. Nonflavanoid phenols\n9. Proanthocyanins\n10. Color intensity\n11. Hue\n12. OD280/OD315 of diluted wines\n13. Proline\n\nFor this exercise, use sklearn.tree.DecisionTreeClassifier to build a multi-class predictor, identifying the grape cultivar based on the provided attributes.  To prevent overfitting, train on 70% of the provided data and test on the remaining 30%. \n\nFor tuning, use hyperopt to distribute your training work.  Split your original training dataset into an 80:20 training and validation sets for the purposes of tuning.  You can use an exhaustive tuning method but you may want to use hyperopt to make this more efficient.  If you use hyperopt, be careful that values taken from the search space are transformed into integer values before being applied to your model.\n\nOnce the model is tuned, train your final model using the optimized hyperparameter values.  Use the training and tesing set from your first split to train and then evaluate this model.\n\nNo data transformations should be performed for this exercise. There are no missing values in the dataset and the dataset is well stratified across the three cultivars. Be sure to provide accuracy scores where indicated below."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c4502757-c9e1-4f90-9472-f97d7c64ed57","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# notebook config\nUSER_NAME = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\nFILE_STORE_ROOT = '/FileStore/shared_uploads/'+USER_NAME"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"92a2dd15-fb6a-498e-8a3e-8ac75e45113b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# examine the file\nfile_name = FILE_STORE_ROOT+'/wine/wine.csv'\ndbutils.fs.head(file_name)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"683bda63-e258-433d-9381-8510d7fbcc5f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["Out[2]: 'cultivar,alchohol,malicacid,ash,alcalinity,magnesium,phenols,flavanoids,nonflavanoids,proanthocyanins,colorintensity,hue,od280,proline\\n1,14.23,1.71,2.43,15.6,127,2.8,3.06,.28,2.29,5.64,1.04,3.92,1065\\n1,13.2,1.78,2.14,11.2,100,2.65,2.76,.26,1.28,4.38,1.05,3.4,1050\\n1,13.16,2.36,2.67,18.6,101,2.8,3.24,.3,2.81,5.68,1.03,3.17,1185\\n1,14.37,1.95,2.5,16.8,113,3.85,3.49,.24,2.18,7.8,.86,3.45,1480\\n1,13.24,2.59,2.87,21,118,2.8,2.69,.39,1.82,4.32,1.04,2.93,735\\n1,14.2,1.76,2.45,15.2,112,3.27,3.39,.34,1.97,6.75,1.05,2.85,1450\\n1,14.39,1.87,2.45,14.6,96,2.5,2.52,.3,1.98,5.25,1.02,3.58,1290\\n1,14.06,2.15,2.61,17.6,121,2.6,2.51,.31,1.25,5.05,1.06,3.58,1295\\n1,14.83,1.64,2.17,14,97,2.8,2.98,.29,1.98,5.2,1.08,2.85,1045\\n1,13.86,1.35,2.27,16,98,2.98,3.15,.22,1.85,7.22,1.01,3.55,1045\\n1,14.1,2.16,2.3,18,105,2.95,3.32,.22,2.38,5.75,1.25,3.17,1510\\n1,14.12,1.48,2.32,16.8,95,2.2,2.43,.26,1.57,5,1.17,2.82,1280\\n1,13.75,1.73,2.41,16,89,2.6,2.76,.29,1.81,5.6,1.15,2.9,1320\\n1,14.75,1.73,2.39,11.4,91,3.1,3.69,.43,2.81,5.4,1.25,2.73,1150\\n1,14.38,1.87,2.38,12,102,3.3,3.64,.29,2.96,7.5,1.2,3,1547\\n1,13.63,1.81,2.7,17.2,112,2.85,2.91,.3,1.46,7.3,1.28,2.88,1310\\n1,14.3,1.92,2.72,20,120,2.8,3.14,.33,1.97,6.2,1.07,2.65,1280\\n1,13.83,1.57,2.62,20,115,2.95,3.4,.4,1.72,6.6,1.13,2.57,1130\\n1,14.19,1.59,2.48,16.5,108,3.3,3.93,.32,1.86,8.7,1.23,2.82,1680\\n1,13.64,3.1,2.56,15.2,116,2.7,3.03,.17,1.66,5.1,.96,3.36,845\\n1,14.06,1.63,2.28,16,126,3,3.17,.24,2.1,5.65,1.09,3.71,780\\n1,12.93,3.8,2.65,18.6,102,2.41,2.41,.25,1.98,4.5,1.03,3.52,770\\n1,13.71,1.86,2.36,16.6,101,2.61,2.88,.27,1.69,3.8,1.11,4,1035\\n1,12.85,1.6,2.52,17.8,95,2.48,2.37,.26,1.46,3.93,1.09,3.63,1015\\n1,13.5,1.81,2.61,20,96,2.53,2.61,.28,1.66,3.52,1.12,3.82,845\\n1,13.05,2.05,3.22,25,124,2.63,2.68,.47,1.92,3.58,1.13,3.2,830\\n1,13.39,1.77,2.62,16.1,93,2.85,2.94,.34,1.45,4.8,.92,3.22,1195\\n1,13.3,1.72,2.14,17,94,2.4,2.19,.27,1.35,3.95,1.02,2.77,1285\\n1,13.87,1.9,2.8,19.4,107,2.95,2.97,.37,1.76,4.5,1.25,3.4,915\\n1,14.02,1.68,2.21,16,96,2.65,2.33,.26,1.98,4.7,1.04,3.59,1035\\n1,13.73,1.5,2.7,22.5,101,3,3.25,.29,2.38,5.7,1.19,2.71,1285\\n1,13.58,1.66,2.36,19.1,106,2.86,3.19,.22,1.95,6.9,1.09,2.88,1515\\n1,13.68,1.83,2.36,17.2,104,2.42,2.69,.42,1.97,3.84,1.23,2.87,990\\n1,13.76,1.53,2.7,19.5,132,2.95,2.74,.5,1.35,5.4,1.25,3,1235\\n1,13.51,1.8,2.65,19,110,2.35,2.53,.29,1.54,4.2,1.1,2.87,1095\\n1,13.48,1.81,2.41,20.5,100,2.7,2.98,.26,1.86,5.1,1.04,3.47,920\\n1,13.28,1.64,2.84,15.5,110,2.6,2.68,.34,1.36,4.6,1.09,2.78,880\\n1,13.05,1.65,2.55,18,98,2.45,2.43,.29,1.44,4.25,1.12,2.51,1105\\n1,13.07,1.5,2.1,15.5,98,2.4,2.64,.28,1.37,3.7,1.18,2.69,1020\\n1,14.22,3.99,2.51,13.2,128,3,3.04,.2,2.08,5.1,.89,3.53,760\\n1,13.56,1.71,2.31,16.2,117,3.15,3.29,.34,2.34,6.13,.95,3.38,795\\n1,13.41,3.84,2.12,18.8,90,2.45,2.68,.27,1.48,4.28,.91,3,1035\\n1,13.88,1.89,2.59,15,101,3.25,3.56,.17,1.7,5.43,.88,3.56,1095\\n1,13.24,3.98,2.29,17.5,103,2.64,2.63,.32,1.66,4.36,.82,3,680\\n1,13.05,1.77,2.1,17,107,3,3,.28,2.03,5.04,.88,3.35,885\\n1,14.21,4.04,2.44,18.9,111,2.85,2.65,.3,1.25,5.24,.87,3.33,1080\\n1,14.38,3.59,2.28,16,102,3.25,3.17,.27,2.19,4.9,1.04,3.44,1065\\n1,13.9,1.68,2.12,16,101,3.1,3.39,.21,2.14,6.1,.91,3.33,985\\n1,14.1,2.02,2.4,18.8,103,2.75,2.92,.32,2.38,6.2,1.07,2.75,1060\\n1,13.94,1.73,2.27,17.4,108,2.88,3.54,.32,2.08,8.90,1.12,3.1,1260\\n1,13.05,1.73,2.04,12.4,92,2.72,3.27,.17,2.91,7.2,1.12,2.91,1150\\n1,13.83,1.65,2.6,17.2,94,2.45,2.99,.22,2.29,5.6,1.24,3.37,1265\\n1,13.82,1.75,2.42,14,111,3.88,3.74,.32,1.87,7.05,1.01,3.26,1190\\n1,13.77,1.9,2.68,17.1,115,3,2.79,.39,1.68,6.3,1.13,2.93,1375\\n1,13.74,1.67,2.25,16.4,118,2.6,2.9,.21,1.62,5.85,.92,3.2,1060\\n1,13.56,1.73,2.46,20.5,116,2.96,2.78,.2,2.45,6.25,.98,3.03,1120\\n1,14.22,1.7,2.3,16.3,118,3.2,3,.26,2.03,6.38,.94,3.31,970\\n1,13.29,1.97,2.68,16.8,102,3,3.23,.31,1.66,6,1.07,2.84,1270\\n1,13.72,1.43,2.5,16.7,108,3.4,3.67,.19,2.04,6.8,.89,2.87,1285\\n2,12.37,.94,1.36,10.6,88,1.98,.57,.28,.42,1.95,1.05,1.82,520\\n2,12.33,1.1,2.28,16,101,2.05,1.09,.63,.41,3.27,1.25,1.67,680\\n2,12.64,1.36,2.02,16.8,100,2.02,1.41,.53,.62,5.75,.98,1.59,450\\n2,13.67,1.25,1.92,18,94,2.1,1.79,.32,.73,3.8,1.23,2.46,630\\n2,12.37,1.13,2.16,19,87,3.5,3.1,.19,1.87,4.45,1.22,2.87,420\\n2,12.17,1.45,2.53,19,104,1.89,1.75,.45,1.03,2.95,1.45,2.23,355\\n2,12.37,1.21,2.56,18.1,98,2.42,2.65,.37,2.08,4.6,1.19,2.3,678\\n2,13.11,1.01,1.7,15,78,2.98,3.18,.26,2.28,5.3,1.12,3.18,502\\n2,12.37,1.17,1.92,19.6,78,2.11,2,.27,1.04,4.68,1.12,3.48,510\\n2,13.34,.94,2.36,17,110,2.53,1.3,.55,.42,3.17,1.02,1.93,750\\n2,12.21,1.19,1.75,16.8,151,1.85,1.28,.14,2.5,2.85,1.28,3.07,718\\n2,12.29,1.61,2.21,20.4,103,1.1,1.02,.37,1.46,3.05,.906,1.82,870\\n2,13.86,1.51,2.67,25,86,2.95,2.86,.21,1.87,3.38,1.36,3.16,410\\n2,13.49,1.66,2.24,24,87,1.88,1.84,.27,1.03,3.74,.98,2.78,472\\n2,12.99,1.67,2.6,30,139,3.3,2.89,.21,1.96,3.35,1.31,3.5,985\\n2,11.96,1.09,2.3,21,101,3.38,2.14,.13,1.65,3.21,.99,3.13,886\\n2,11.66,1.88,1.92,16,97,1.61,1.57,.34,1.15,3.8,1.23,2.14,428\\n2,13.03,.9,1.71,16,86,1.95,2.03,.24,1.46,4.6,1.19,2.48,392\\n2,11.84,2.89,2.23,18,112,1.72,1.32,.43,.95,2.65,.96,2.52,500\\n2,12.33,.99,1.95,14.8,136,1.9,1.85,.35,2.76,3.4,1.06,2.31,750\\n2,12.7,3.87,2.4,23,101,2.83,2.55,.43,1.95,2.57,1.19,3.13,463\\n2,12,.92,2,19,86,2.42,2.26,.3,1.43,2.5,1.38,3.12,278\\n2,12.72,1.81,2.2,18.8,86,2.2,2.53,.26,1.77,3.9,1.16,3.14,714\\n2,12.08,1.13,2.51,24,78,2,1.58,.4,1.4,2.2,1.31,2.72,630\\n2,13.05,3.86,2.32,22.5,85,1.65,1.59,.61,1.62,4.8,.84,2.01,515\\n2,11.84,.89,2.58,18,94,2.2,2.21,.22,2.35,3.05,.79,3.08,520\\n2,12.67,.98,2.24,18,99,2.2,1.94,.3,1.46,2.62,1.23,3.16,450\\n2,12.16,1.61,2.31,22.8,90,1.78,1.69,.43,1.56,2.45,1.33,2.26,495\\n2,11.65,1.67,2.62,26,88,1.92,1.61,.4,1.34,2.6,1.36,3.21,562\\n2,11.64,2.06,2.46,21.6,84,1.95,1.69,.48,1.35,2.8,1,2.75,680\\n2,12.08,1.33,2.3,23.6,70,2.2,1.59,.42,1.38,1.74,1.07,3.21,625\\n2,12.08,1.83,2.32,18.5,81,1.6,1.5,.52,1.64,2.4,1.08,2.27,480\\n2,12,1.51,2.42,22,86,1.45,1.25,.5,1.63,3.6,1.05,2.65,450\\n2,12.69,1.53,2.26,20.7,80,1.38,1.46,.58,1.62,3.05,.96,2.06,495\\n2,12.29,2.83,2.22,18,88,2.45,2.25,.25,1.99,2.15,1.15,3.3,290\\n2,11.62,1.99,2.28,18,98,3.02,2.26,.17,1.35,3.25,1.16,2.96,345\\n2,12.47,1.52,2.2,19,162,2.5,2.27,.32,3.28,2.6,1.16,2.63,937\\n2,11.81,2.12,2.74,21.5,134,1.6,.99,.14,1.56,2.5,.95,2.26,625\\n2,12.29,1.41,1.98,16,85,2.55,2.5,.29,1.77,2.9,1.23,2.74,428\\n2,12.37,1.07,2.1,18.5,88,3.52,3.75,.24,1.95,4.5,1.04,2.77,660\\n2,12.29,3.17,2.21,18,88,2.85,2.99,.45,2.81,2.3,1.42,2.83,406\\n2,12.08,2.08,1.7,17.5,97,2.23,2.17,.26,1.4,3.3,1.27,2.96,710\\n2,12.6,1.34,1.9,18.5,88,1.45,1.36,.29,1.35,2.45,1.04,2.77,562\\n2,12.34,2.45,2.46,21,98,2.56,2.11,.34,1.31,2.8,.8,3.38,438\\n2,11.82,1.72,1.88,19.5,86,2.5,1.64,.37,1.42,2.06,.94,2.44,415\\n2,12.51,1.73,1.98,20.5,85,2.2,1.92,.32,1.48,2.94,1.04,3.57,672\\n2,12.42,2.55,2.27,22,90,1.68,1.84,.66,1.42,2.7,.86,3.3,315\\n2,12.25,1.73,2.12,19,80,1.65,2.03,.37,1.63,3.4,1,3.17,510\\n2,12.72,1.75,2.28,22.5,84,1.38,1.76,.48,1.63,3.3,.88,2.42,488\\n2,12.22,1.29,1.94,19,92,2.36,2.04,.39,2.08,2.7,.86,3.02,312\\n2,11.61,1.35,2.7,20,94,2.74,2.92,.29,2.49,2.65,.96,3.26,680\\n2,11.46,3.74,1.82,19.5,107,3.18,2.58,.24,3.58,2.9,.75,2.81,562\\n2,12.52,2.43,2.17,21,88,2.55,2.27,.26,1.22,2,.9,2.78,325\\n2,11.76,2.68,2.92,20,103,1.75,2.03,.6,1.05,3.8,1.23,2.5,607\\n2,11.41,.74,2.5,21,88,2.48,2.01,.42,1.44,3.08,1.1,2.31,434\\n2,12.08,1.39,2.5,22.5,84,2.56,2.29,.43,1.04,2.9,.93,3.19,385\\n2,11.03,1.51,2.2,21.5,85,2.46,2.17,.52,2.01,1.9,1.71,2.87,407\\n2,11.82,1.47,1.99,20.8,86,1.98,1.6,.3,1.53,1.95,.95,3.33,495\\n2,12.42,1.61,2.19,22.5,108,2,2.09,.34,1.61,2.06,1.06,2.96,345\\n2,12.77,3.43,1.98,16,80,1.63,1.25,.43,.83,3.4,.7,2.12,372\\n2,12,3.43,2,19,87,2,1.64,.37,1.87,1.28,.93,3.05,564\\n2,11.45,2.4,2.42,20,96,2.9,2.79,.32,1.83,3.25,.8,3.39,625\\n2,11.56,2.05,3.23,28.5,119,3.18,5.08,.47,1.87,6,.93,3.69,465\\n2,12.42,4.43,2.73,26.5,102,2.2,2.13,.43,1.71,2.08,.92,3.12,365\\n2,13.05,5.8,2.13,21.5,86,2.62,2.65,.3,2.01,2.6,.73,3.1,380\\n2,11.87,4.31,2.39,21,82,2.86,3.03,.21,2.91,2.8,.75,3.64,380\\n2,12.07,2.16,2.17,21,85,2.6,2.65,.37,1.35,2.76,.86,3.28,378\\n2,12.43,1.53,2.29,21.5,86,2.74,3.15,.39,1.77,3.94,.69,2.84,352\\n2,11.79,2.13,2.78,28.5,92,2.13,2.24,.58,1.76,3,.97,2.44,466\\n2,12.37,1.63,2.3,24.5,88,2.22,2.45,.4,1.9,2.12,.89,2.78,342\\n2,12.04,4.3,2.38,22,80,2.1,1.75,.42,1.35,2.6,.79,2.57,580\\n3,12.86,1.35,2.32,18,122,1.51,1.25,.21,.94,4.1,.76,1.29,630\\n3,12.88,2.99,2.4,20,104,1.3,1.22,.24,.83,5.4,.74,1.42,530\\n3,12.81,2.31,2.4,24,98,1.15,1.09,.27,.83,5.7,.66,1.36,560\\n3,12.7,3.55,2.36,21.5,106,1.7,1.2,.17,.84,5,.78,1.29,600\\n3,12.51,1.24,2.25,17.5,85,2,.58,.6,1.25,5.45,.75,1.51,650\\n3,12.6,2.46,2.2,18.5,94,1.62,.66,.63,.94,7.1,.73,1.58,695\\n3,12.25,4.72,2.54,21,89,1.38,.47,.53,.8,3.85,.75,1.27,720\\n3,12.53,5.51,2.64,25,96,1.79,.6,.63,1.1,5,.82,1.69,515\\n3,13.49,3.59,2.19,19.5,88,1.62,.48,.58,.88,5.7,.81,1.82,580\\n3,12.84,2.96,2.61,24,101,2.32,.6,.53,.81,4.92,.89,2.15,590\\n3,12.93,2.81,2.7,21,96,1.54,.5,.53,.75,4.6,.77,2.31,600\\n3,13.36,2.56,2.35,20,89,1.4,.5,.37,.64,5.6,.7,2.47,780\\n3,13.52,3.17,2.72,23.5,97,1.55,.52,.5,.55,4.35,.89,2.06,520\\n3,13.62,4.95,2.35,20,92,2,.8,.47,1.02,4.4,.91,2.05,550\\n3,12.25,3.88,2.2,18.5,112,1.38,.78,.29,1.14,8.21,.65,2,855\\n3,13.16,3.57,2.15,21,102,1.5,.55,.43,1.3,4,.6,1.68,830\\n3,13.88,5.04,2.23,20,80,.98,.34,.4,.68,4.9,.58,1.33,415\\n3,12.87,4.61,2.48,21.5,86,1.7,.65,.47,.86,7.65,.54,1.86,625\\n3,13.32,3.24,2.38,21.5,92,1.93,.76,.45,1.25,8.42,.55,1.62,650\\n3,13.08,3.9,2.36,21.5,113,1.41,1.39,.34,1.14,9.40,.57,1.33,550\\n3,13.5,3.12,2.62,24,123,1.4,1.57,.22,1.25,8.60,.59,1.3,500\\n3,12.79,2.67,2.48,22,112,1.48,1.36,.24,1.26,10.8,.48,1.47,480\\n3,13.11,1.9,2.75,25.5,116,2.2,1.28,.26,1.56,7.1,.61,1.33,425\\n3,13.23,3.3,2.28,18.5,98,1.8,.83,.61,1.87,10.52,.56,1.51,675\\n3,12.58,1.29,2.1,20,103,1.48,.58,.53,1.4,7.6,.58,1.55,640\\n3,13.17,5.19,2.32,22,93,1.74,.63,.61,1.55,7.9,.6,1.48,725\\n3,13.84,4.12,2.38,19.5,89,1.8,.83,.48,1.56,9.01,.57,1.64,480\\n3,12.45,3.03,2.64,27,97,1.9,.58,.63,1.14,7.5,.67,1.73,880\\n3,14.34,1.68,2.7,25,98,2.8,1.31,.53,2.7,13,.57,1.96,660\\n3,13.48,1.67,2.64,22.5,89,2.6,1.1,.52,2.29,11.75,.57,1.78,620\\n3,12.36,3.83,2.38,21,88,2.3,.92,.5,1.04,7.65,.56,1.58,520\\n3,13.69,3.26,2.54,20,107,1.83,.56,.5,.8,5.88,.96,1.82,680\\n3,12.85,3.27,2.58,22,106,1.65,.6,.6,.96,5.58,.87,2.11,570\\n3,12.96,3.45,2.35,18.5,106,1.39,.7,.4,.94,5.28,.68,1.75,675\\n3,13.78,2.76,2.3,22,90,1.35,.68,.41,1.03,9.58,.7,1.68,615\\n3,13.73,4.36,2.26,22.5,88,1.28,.47,.52,1.15,6.62,.78,1.75,520\\n3,13.45,3.7,2.6,23,111,1.7,.92,.43,1.46,10.68,.85,1.56,695\\n3,12.82,3.37,2.3,19.5,88,1.48,.66,.4,.97,10.26,.72,1.75,685\\n3,13.58,2.58,2.69,24.5,105,1.55,.84,.39,1.54,8.66,.74,1.8,750\\n3,13.4,4.6,2.86,25,112,1.98,.96,.27,1.11,8.5,.67,1.92,630\\n3,12.2,3.03,2.32,19,96,1.25,.49,.4,.73,5.5,.66,1.83,510\\n3,12.77,2.39,2.28,19.5,86,1.39,.51,.48,.64,9.899999,.57,1.63,470\\n3,14.16,2.51,2.48,20,91,1.68,.7,.44,1.24,9.7,.62,1.71,660\\n3,13.71,5.65,2.45,20.5,95,1.68,.61,.52,1.06,7.7,.64,1.74,740\\n3,13.4,3.91,2.48,23,102,1.8,.75,.43,1.41,7.3,.7,1.56,750\\n3,13.27,4.28,2.26,20,120,1.59,.69,.43,1.35,10.2,.59,1.56,835\\n3,13.17,2.59,2.37,20,120,1.65,.68,.53,1.46,9.3,.6,1.62,840\\n3,14.13,4.1,2.74,24.5,96,2.05,.76,.56,1.35,9.2,.61,1.6,560\\n'"]}],"execution_count":0},{"cell_type":"code","source":["# read the data to a pandas DataFrame and assemble feature and label arrays\nfrom pyspark.sql.types import *\n\nschema = StructType([\n  StructField('cultivar', IntegerType()),\n  StructField('alcohol', FloatType()),\n  StructField('malicacid', FloatType()),\n  StructField('ash', FloatType()),\n  StructField('alcalinity', FloatType()),\n  StructField('magnesium', FloatType()),\n  StructField('phenols', FloatType()),\n  StructField('flavanoids', FloatType()),\n  StructField('nonflavanoids', FloatType()),\n  StructField('proanthocyanins', FloatType()),\n  StructField('colorintensity', FloatType()),\n  StructField('hue', FloatType()),\n  StructField('od280', FloatType()),\n  StructField('proline', FloatType())\n  ])\n \nwine = (\n  (\n   spark\n    .read\n    .csv(file_name, sep=',', header=True, schema=schema)\n  ).toPandas()\n  )\n \nwine.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2baea2fe-9fc1-4cac-a711-a16b3b060f83","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cultivar</th>\n      <th>alcohol</th>\n      <th>malicacid</th>\n      <th>ash</th>\n      <th>alcalinity</th>\n      <th>magnesium</th>\n      <th>phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoids</th>\n      <th>proanthocyanins</th>\n      <th>colorintensity</th>\n      <th>hue</th>\n      <th>od280</th>\n      <th>proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.600000</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.200000</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.600000</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.799999</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.000000</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cultivar</th>\n      <th>alcohol</th>\n      <th>malicacid</th>\n      <th>ash</th>\n      <th>alcalinity</th>\n      <th>magnesium</th>\n      <th>phenols</th>\n      <th>flavanoids</th>\n      <th>nonflavanoids</th>\n      <th>proanthocyanins</th>\n      <th>colorintensity</th>\n      <th>hue</th>\n      <th>od280</th>\n      <th>proline</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>14.23</td>\n      <td>1.71</td>\n      <td>2.43</td>\n      <td>15.600000</td>\n      <td>127.0</td>\n      <td>2.80</td>\n      <td>3.06</td>\n      <td>0.28</td>\n      <td>2.29</td>\n      <td>5.64</td>\n      <td>1.04</td>\n      <td>3.92</td>\n      <td>1065.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>13.20</td>\n      <td>1.78</td>\n      <td>2.14</td>\n      <td>11.200000</td>\n      <td>100.0</td>\n      <td>2.65</td>\n      <td>2.76</td>\n      <td>0.26</td>\n      <td>1.28</td>\n      <td>4.38</td>\n      <td>1.05</td>\n      <td>3.40</td>\n      <td>1050.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>13.16</td>\n      <td>2.36</td>\n      <td>2.67</td>\n      <td>18.600000</td>\n      <td>101.0</td>\n      <td>2.80</td>\n      <td>3.24</td>\n      <td>0.30</td>\n      <td>2.81</td>\n      <td>5.68</td>\n      <td>1.03</td>\n      <td>3.17</td>\n      <td>1185.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>14.37</td>\n      <td>1.95</td>\n      <td>2.50</td>\n      <td>16.799999</td>\n      <td>113.0</td>\n      <td>3.85</td>\n      <td>3.49</td>\n      <td>0.24</td>\n      <td>2.18</td>\n      <td>7.80</td>\n      <td>0.86</td>\n      <td>3.45</td>\n      <td>1480.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>13.24</td>\n      <td>2.59</td>\n      <td>2.87</td>\n      <td>21.000000</td>\n      <td>118.0</td>\n      <td>2.80</td>\n      <td>2.69</td>\n      <td>0.39</td>\n      <td>1.82</td>\n      <td>4.32</td>\n      <td>1.04</td>\n      <td>2.93</td>\n      <td>735.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# split the data into training and test data sets\nfrom sklearn.model_selection import train_test_split\n \n# extract data for fitting\nX = wine.drop('cultivar', axis=1) # features\ny = wine['cultivar'] # labels\n \nX_train, X_test, y_train, y_test = train_test_split(\n  X, y, \n  test_size = 0.3, \n  random_state=42, \n  stratify=y\n  )"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"20ca3c92-cd31-443a-9e1a-0cfc9eebfd37","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# split the training data into training and validation datasets\nX_train_train, X_train_validate, y_train_train, y_train_validate = train_test_split(\n  X_train, y_train, \n  stratify=y_train, train_size=0.8\n  ) "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b1735bcb-e228-4377-8d70-83746462fc7f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# tune your model on the training/validation sets, leveraging hyperopt\n# determine an optimal value for:\n# max_depth between 1 and 10\n# max_features between 1 and 13\n# all other features are allowed to remain at their defaults\nfrom hyperopt import hp, fmin, tpe, SparkTrials, STATUS_OK, space_eval\n \n#define hyperopt seach space\nsearch_space = {\n  'max_depth' : hp.quniform('max_depth', 1, 10, 1),\n  'max_features' : hp.quniform('max_features', 1, 13, 1)\n}\n \n#send copies of training and validation sets to workers in cluster \nX_train_train_broadcast = sc.broadcast(X_train_train)\ny_train_train_broadcast = sc.broadcast(y_train_train)\nX_train_validate_broadcast = sc.broadcast(X_train_validate)\ny_train_validate_broadcast = sc.broadcast(y_train_validate)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b030f893-1568-412d-873a-760062420c07","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# train your model using the optimized parameters and your first training set\nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.metrics import accuracy_score\n\ndef evaluate_model(hyperopt_params):\n  \n  # accesss replicated input data\n  X_train_input = X_train_train_broadcast.value\n  y_train_input = y_train_train_broadcast.value\n  X_validate_input = X_train_validate_broadcast.value\n  y_validate_input = y_train_validate_broadcast.value  \n  \n  # configure model parameters\n  params = hyperopt_params\n \n  # adjust hyperopt-supplied params\n  if 'max_depth' in params: params['max_depth']=int(params['max_depth'])   # hyperopt supplies values as float but must be int\n  if 'max_features' in params: params['max_features']=int(params['max_features']) # hyperopt supplies values as float but must be int\n  \n  # instantiate model with parameters \n  dt = DecisionTreeClassifier(**params)\n  \n  # train and predict X validate input\n  dt.fit(X_train_input, y_train_input)\n  pred = dt.predict(X_validate_input)\n  \n  # get accuracy score\n  acc = accuracy_score(y_validate_input, pred)\n  \n  # invert metric for hyperopt\n  loss = -1 * acc\n  \n  # return results \n  return {'loss': loss, 'status': STATUS_OK}\n \n# utilize fmin \nargmin = fmin(\n  fn=evaluate_model,\n  space=search_space,\n  algo=tpe.suggest,  # algorithm controlling how hyperopt navigates the search space\n  max_evals=20,\n  trials=SparkTrials(parallelism=4),\n  verbose=True\n  )\n \nprint(argmin)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"41561928-cb0d-42a2-9434-1394ce619a84","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stderr","text":["Hyperopt with SparkTrials will automatically track trials in MLflow. To view the MLflow experiment associated with the notebook, click the 'Runs' icon in the notebook context bar on the upper right. There, you can view all runs.\nTo view logs from trials, please check the Spark executor logs. To view executor logs, expand 'Spark Jobs' above until you see the (i) icon next to the stage from the trial job. Click it and find the list of tasks. Click the 'stderr' link for a task to view trial logs.\n"]},{"output_type":"stream","output_type":"stream","name":"stdout","text":["\r  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]\r  5%|▌         | 1/20 [00:06<01:56,  6.13s/trial, best loss: -0.88]\r 10%|█         | 2/20 [00:09<01:18,  4.34s/trial, best loss: -0.92]\r 15%|█▌        | 3/20 [00:10<00:48,  2.85s/trial, best loss: -0.96]\r 20%|██        | 4/20 [00:12<00:40,  2.52s/trial, best loss: -0.96]\r 25%|██▌       | 5/20 [00:13<00:29,  1.97s/trial, best loss: -0.96]\r 30%|███       | 6/20 [00:16<00:32,  2.33s/trial, best loss: -0.96]\r 35%|███▌      | 7/20 [00:18<00:28,  2.22s/trial, best loss: -0.96]\r 45%|████▌     | 9/20 [00:20<00:17,  1.63s/trial, best loss: -0.96]\r 50%|█████     | 10/20 [00:23<00:19,  1.99s/trial, best loss: -0.96]\r 55%|█████▌    | 11/20 [00:25<00:17,  1.99s/trial, best loss: -0.96]\r 60%|██████    | 12/20 [00:27<00:15,  2.00s/trial, best loss: -0.96]\r 65%|██████▌   | 13/20 [00:28<00:12,  1.72s/trial, best loss: -0.96]\r 70%|███████   | 14/20 [00:30<00:10,  1.80s/trial, best loss: -0.96]\r 75%|███████▌  | 15/20 [00:32<00:09,  1.86s/trial, best loss: -0.96]\r 80%|████████  | 16/20 [00:35<00:08,  2.20s/trial, best loss: -0.96]\r 85%|████████▌ | 17/20 [00:36<00:05,  1.85s/trial, best loss: -0.96]\r 90%|█████████ | 18/20 [00:37<00:03,  1.60s/trial, best loss: -0.96]\r 95%|█████████▌| 19/20 [00:38<00:01,  1.42s/trial, best loss: -0.96]\r100%|██████████| 20/20 [00:39<00:00,  1.30s/trial, best loss: -0.96]\r100%|██████████| 20/20 [00:39<00:00,  1.97s/trial, best loss: -0.96]\n"]},{"output_type":"stream","output_type":"stream","name":"stderr","text":["Total Trials: 20: 20 succeeded, 0 failed, 0 cancelled.\n"]},{"output_type":"stream","output_type":"stream","name":"stdout","text":["{'max_depth': 3.0, 'max_features': 6.0}\n"]}],"execution_count":0},{"cell_type":"code","source":["# score your model using the test data\n# configure model parameters\nparams = argmin\n\n# adjust hyperopt-supplied params \nif 'max_depth' in params: params['max_depth']=int(params['max_depth'])   # hyperopt supplies values as float but must be int\nif 'max_features' in params: params['max_features']=int(params['max_features']) # hyperopt supplies values as float but must be int\ndt = DecisionTreeClassifier(**params)\ndt.fit(X_train, y_train)\n \n# score model \npred = dt.predict(X_test)\nacc = accuracy_score(y_test, pred)\n \nprint(acc)\n \n# release broadcast from memory \nX_train_train_broadcast.destroy()\ny_train_train_broadcast.destroy()\nX_train_validate_broadcast.destroy()\ny_train_validate_broadcast.destroy()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"68b07eb6-7211-4f8d-a6bc-09742420a644","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["0.9259259259259259\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ML with Spark Project","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1747338989314986}},"nbformat":4,"nbformat_minor":0}
